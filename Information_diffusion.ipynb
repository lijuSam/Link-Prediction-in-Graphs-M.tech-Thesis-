{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Information_diffusion.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOXO3B1te4IancPXm4wcbzP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lijuSam/Link-Prediction-in-Graphs-M.tech-Thesis-/blob/main/Information_diffusion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1MBiEJIW3Z0"
      },
      "outputs": [],
      "source": [
        "import networkx as nx  # execution time : 29m 31s with facebook data 1912.edges loop=2 and all =2\n",
        "\n",
        "import numpy as np\n",
        "import numpy\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import (precision_recall_curve,PrecisionRecallDisplay)\n",
        "from matplotlib import pyplot\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "\n",
        "from clustering_ss_review import clustering_ss_eval, clustering_recall_correct, data_to_adj_review\n",
        "\n",
        "import time\n",
        "from xlwt import Workbook\n",
        "import os\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    starttime = time.time()\n",
        "    var_dict_main = {}\n",
        "\n",
        "\n",
        "    def auprgraph_range(adj,file_name):\n",
        "        os.makedirs('result_range_review', exist_ok=True)\n",
        "        G = nx.Graph(adj)\n",
        "        print(\"nodes - \" + str(len(adj)) + \" edges - \" + str(len(G.edges))+\" name - \"+str(file_name))\n",
        "        file = open('./result_range_review/' + file_name + \".txt\", 'a')\n",
        "        #tao_array = [5, 10, 15, 20, 25]\n",
        "        tao_array = [5, 10]\n",
        "        #theta_array = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
        "        theta_array = [0.1]\n",
        "        for tao in tao_array:\n",
        "            for theta in theta_array:\n",
        "                ratio = []\n",
        "                aupr = []\n",
        "                recall = []\n",
        "                auc = []\n",
        "                avg_prec = []\n",
        "                acc_score = []  \n",
        "                           \n",
        "                starttime_single = time.time()\n",
        "                for i in np.arange(0.5, 1, 0.1):  # range is the fraction of edge values included in the graph\n",
        "                    print(\n",
        "                        \"nodes - \" + str(len(adj)) + \" edges - \" + str(len(G.edges)) + \" name - \" + str(file_name))\n",
        "                    print(\"For tao : \", tao)\n",
        "                    print(\"For theta : \", theta)\n",
        "                    print(\"For ratio : \", i - 1)\n",
        "                    avg_range_return = avg_range(G, file_name, tao, theta, i)\n",
        "                    aupr.append(avg_range_return[0])\n",
        "                    recall.append(avg_range_return[1])\n",
        "                    auc.append(avg_range_return[2])\n",
        "                    avg_prec.append(avg_range_return[3])\n",
        "                    acc_score.append(avg_range_return[4])\n",
        "                                       \n",
        "                    \n",
        "                    ratio.append(i - 1)\n",
        "                endtime_single = time.time()\n",
        "                result = \"\\nFor tao - \"+str(tao)+\" and for theta - \"+str(theta)+\"\\nRatio :\"+str(ratio)+\"\\nAUPR : \"+ str(aupr) + \"\\nRecall : \" +str(recall)+\"\\nAUC : \"+str(auc)+\"\\nAvg Prec : \"+str(avg_prec)+\"\\nAccuracy score : \"+str(acc_score)+\"\\nTime : \"+str((endtime_single - starttime_single))+\"sec\\n\"\n",
        "                print(str(result))\n",
        "                file.write(result)\n",
        "\n",
        "\n",
        "                # plot the recall precision curve for the model              \n",
        "\n",
        "                pyplot.plot(recall, avg_prec, marker='.', label='CLP ID')\n",
        "                # axis labels\n",
        "                pyplot.xlabel('Recall')\n",
        "                pyplot.ylabel('Precision')\n",
        "                # show the legend\n",
        "                pyplot.legend()\n",
        "                # show the plot\n",
        "                pyplot.show()       \n",
        "\n",
        "\n",
        "              \n",
        "                \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                # Workbook is created\n",
        "                wb = Workbook()\n",
        "                # add_sheet is used to create sheet.\n",
        "                sheet1 = wb.add_sheet('Sheet 1',cell_overwrite_ok=True)\n",
        "                sheet1.write(0, 0, 'Ratio')\n",
        "                sheet1.write(0, 1, 'AUPR')\n",
        "                sheet1.write(0, 2, 'RECALL')\n",
        "                sheet1.write(0, 3, 'AUC')\n",
        "                sheet1.write(0, 4, 'AVG PRECISION')\n",
        "                sheet1.write(0, 5, 'ACCURACY SCORE')\n",
        "                for i in range(5):\n",
        "                    sheet1.write(i + 1, 0, ratio[i])\n",
        "                    sheet1.write(i + 1, 1, aupr[i])\n",
        "                    sheet1.write(i + 1, 2, recall[i])\n",
        "                    sheet1.write(i + 1, 3, auc[i])\n",
        "                    sheet1.write(i + 1, 4, avg_prec[i])\n",
        "                    sheet1.write(i + 1, 5, acc_score[i])\n",
        "                wb.save('./result_range_review/' + file_name + \"_\"+str(tao)+\"_\"+str(theta)+\".xls\")\n",
        "        file.close()\n",
        "\n",
        "\n",
        "    def avg_range(g, file_name, tao, theta, ratio) :\n",
        "        #full graph\n",
        "        aupr = 0\n",
        "        recall = 0\n",
        "        auc = 0\n",
        "        prec = 0\n",
        "        acc_score = 0\n",
        "        \n",
        "        \n",
        "        #loop = 10\n",
        "        loop = 2\n",
        "        for i in range(loop):\n",
        "            print(\"for ratio - \"+str(ratio))\n",
        "            print(\"iteration number - \" +str(i))\n",
        "\n",
        "            value = clustering_recall_correct(g, file_name, tao, theta, ratio)\n",
        "\n",
        "            aupr += value[0]\n",
        "            recall += value[1]\n",
        "            auc += value[2]\n",
        "            prec += value[3]\n",
        "            acc_score += value[4]\n",
        "            \n",
        "            \n",
        "\n",
        "        return aupr / loop, recall / loop, auc / loop, prec / loop, acc_score / loop\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "    def aupgraph_range_control_multiple_dataset () :\n",
        "        file_name_array_single = ['facebook']\n",
        "        for file_name in file_name_array_single :\n",
        "            ds = './datasets/' + file_name\n",
        "            adj = data_to_adj_review(ds + '.gml') #originally .gml\n",
        "            auprgraph_range(adj[2], file_name)\n",
        "\n",
        "    def cluster_eval_single(adj, file_name):\n",
        "        os.makedirs('result_cluster_eval_review', exist_ok=True)\n",
        "        #tao_array = [5, 10, 15, 20, 25]\n",
        "        tao_array = [5, 10]\n",
        "        #theta_array = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
        "        theta_array = [0.1, 0.2]\n",
        "        G = nx.Graph(adj)\n",
        "        edges = np.array(list(G.edges))\n",
        "        nodes = list(range(len(adj)))\n",
        "        print(\"nodes - \" + str(len(adj)) + \" edges - \" + str(len(G.edges)) + \" name - \" + str(file_name))\n",
        "        np.random.shuffle(edges)\n",
        "        et = edges\n",
        "        nonedges = np.array(list(nx.non_edges(G)))\n",
        "        np.random.shuffle(nonedges)\n",
        "        #loop = 10\n",
        "        loop = 2\n",
        "        file = open('./result_cluster_eval_review/' + file_name + \".txt\", 'a')\n",
        "        cluster_number_matrix = numpy.zeros((5, 10))\n",
        "        average_isolability_matrix = numpy.zeros((5, 10))\n",
        "        external_density_matrix = numpy.zeros((5, 10))\n",
        "        coverage_matrix = numpy.zeros((5, 10))\n",
        "        modularity_matrix = numpy.zeros((5, 10))\n",
        "        for tao in tao_array:\n",
        "            for theta in theta_array:\n",
        "                starttime_single = time.time()\n",
        "                print(\n",
        "                    \"nodes - \" + str(len(adj)) + \" edges - \" + str(len(G.edges)) + \" name - \" + str(\n",
        "                        file_name))\n",
        "                print(\"For tao : \", tao)\n",
        "                print(\"For theta : \", theta)\n",
        "                cluster_number = 0\n",
        "                average_isolability = 0\n",
        "                external_density = 0\n",
        "                coverage = 0\n",
        "                modularity = 0\n",
        "                for i in range(loop):\n",
        "                    print(\"iteration number - \" + str(i))\n",
        "\n",
        "                    item = clustering_ss_eval(G,tao,theta,file_name)\n",
        "\n",
        "                    cluster_number += item[0]\n",
        "                    average_isolability += item[1]\n",
        "                    external_density += item[2]\n",
        "                    coverage += item[3]\n",
        "                    modularity += item[4]\n",
        "                print(\"after cluster_eval\")\n",
        "                endtime_single = time.time()\n",
        "                result = \"\\nFor tao - \" + str(tao) + \" and for theta - \" + str(theta) +  \"\\naverage cluster number = \" + str(\n",
        "                    cluster_number / loop) + \"\\naverage isolability = \" + str(\n",
        "                    average_isolability / loop) + \"\\nexternal density = \" + str(\n",
        "                    external_density / loop) + \"\\ncovergae = \" + str(coverage / loop) + \"\\nmodularity = \" + str(\n",
        "                    modularity / loop) + \"\\nTime : \" + str(\n",
        "                    (endtime_single - starttime_single)) + \"sec\\n\"\n",
        "                row_index = tao_array.index(tao)\n",
        "                col_index = theta_array.index(theta)\n",
        "                cluster_number_matrix[row_index][col_index] += cluster_number / loop\n",
        "                average_isolability_matrix[row_index][col_index] += average_isolability / loop\n",
        "                external_density_matrix[row_index][col_index] += external_density / loop\n",
        "                coverage_matrix[row_index][col_index] += coverage / loop\n",
        "                modularity_matrix[row_index][col_index] += modularity / loop\n",
        "                print(str(result))\n",
        "                file.write(result)\n",
        "        file.close()\n",
        "        # Workbook is created\n",
        "        wb = Workbook()\n",
        "        # add_sheet is used to create sheet.\n",
        "        sheet_cno = wb.add_sheet('CLUSTER_NO',cell_overwrite_ok=True)\n",
        "        sheet_iso = wb.add_sheet('AVG_ISO',cell_overwrite_ok=True)\n",
        "        sheet_exd = wb.add_sheet('EXTRN_DENS',cell_overwrite_ok=True)\n",
        "        sheet_cover = wb.add_sheet('COVERAGE',cell_overwrite_ok=True)\n",
        "        sheet_mod = wb.add_sheet('MODULARITY',cell_overwrite_ok=True)\n",
        "        sheet_write_array = [sheet_cno, sheet_iso, sheet_exd, sheet_cover, sheet_mod]\n",
        "        for sheet_no in range(len(sheet_write_array)) :\n",
        "            count = 1\n",
        "            for tao in tao_array :\n",
        "                tao_label = \"Tao = \"+str(tao)\n",
        "                sheet_write_array[sheet_no].write(count,0,tao_label)\n",
        "                count += 1\n",
        "            count = 1\n",
        "            for theta in theta_array :\n",
        "                theta_label = \"Theta = \"+str(theta)\n",
        "                sheet_write_array[sheet_no].write(0, count, theta_label)\n",
        "                count += 1\n",
        "            for i in range(5):\n",
        "                for j in range(10):\n",
        "                    if sheet_no == 0: sheet_write_array[sheet_no].write(i + 1, j + 1, cluster_number_matrix[i][j]/5)\n",
        "                    if sheet_no == 1: sheet_write_array[sheet_no].write(i + 1, j + 1, average_isolability_matrix[i][j]/5)\n",
        "                    if sheet_no == 2: sheet_write_array[sheet_no].write(i + 1, j + 1, external_density_matrix[i][j]/5)\n",
        "                    if sheet_no == 3: sheet_write_array[sheet_no].write(i + 1, j + 1, coverage_matrix[i][j]/5)\n",
        "                    if sheet_no == 4: sheet_write_array[sheet_no].write(i + 1, j + 1, modularity_matrix[i][j]/5)\n",
        "        wb.save('./result_cluster_eval_review/' + file_name + \".xls\")\n",
        "\n",
        "    def clustering_check_multiple_dataset():\n",
        "        file_name_array_single = ['facebook']\n",
        "\n",
        "        for file_name in file_name_array_single :\n",
        "            ds = './datasets/' + file_name\n",
        "            adj = data_to_adj_review(ds + '.gml')\n",
        "            cluster_eval_single(adj[2], file_name)\n",
        "\n",
        "\n",
        "    aupgraph_range_control_multiple_dataset()\n",
        "    #clustering_check_multiple_dataset()\n",
        "\n",
        "    endtime = time.time()\n",
        "\n",
        "    print('That took {} seconds'.format(time.time() - starttime))"
      ]
    }
  ]
}