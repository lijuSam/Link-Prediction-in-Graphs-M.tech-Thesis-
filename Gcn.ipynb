{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gcn.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOQry60mAX/DlsGDpPxlTlD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lijuSam/Link-Prediction-in-Graphs-M.tech-Thesis-/blob/main/Gcn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCx6-Q6kbuga"
      },
      "outputs": [],
      "source": [
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import networkx as nx\n",
        "#import tensorflow as tf\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "from sklearn.metrics import (precision_recall_curve,PrecisionRecallDisplay)\n",
        "from matplotlib import pyplot\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize as dataframe\n",
        "import pandas as pd\n",
        "edges = pd.read_csv('1912.edges', sep=' ', skiprows=0, header=None, names=['node1','node2'])\n",
        "edges.head()"
      ],
      "metadata": {
        "id": "NVnoopOpdZUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "    g = nx.read_edgelist('1912.edges')\n",
        "    adj = nx.adjacency_matrix(g)\n",
        "    return adj\n",
        "\n",
        " #Create a weight variable with Glorot & Bengio (AISTATS 2010) initialization.\n",
        "def weight_variable_glorot(input_dim, output_dim, name=\"\"):   \n",
        "    init_range = np.sqrt(6.0 / (input_dim + output_dim))\n",
        "    initial = tf.random_uniform(\n",
        "        [input_dim, output_dim], minval=-init_range,\n",
        "        maxval=init_range, dtype=tf.float32)\n",
        "    return tf.Variable(initial, name=name)\n",
        "\n",
        "\n",
        "def dropout_sparse(x, keep_prob, num_nonzero_elems):\n",
        "    noise_shape = [num_nonzero_elems]\n",
        "    random_tensor = keep_prob\n",
        "    random_tensor += tf.random_uniform(noise_shape)\n",
        "    dropout_mask = tf.cast(tf.floor(random_tensor), dtype=tf.bool)\n",
        "    pre_out = tf.sparse_retain(x, dropout_mask)\n",
        "    return pre_out * (1. / keep_prob)\n",
        "\n",
        "\n",
        "def sparse_to_tuple(sparse_mx):\n",
        "    if not sp.isspmatrix_coo(sparse_mx):\n",
        "        sparse_mx = sparse_mx.tocoo()\n",
        "    coords = np.vstack((sparse_mx.row, sparse_mx.col)).transpose()\n",
        "    values = sparse_mx.data\n",
        "    shape = sparse_mx.shape\n",
        "    return coords, values, shape\n",
        "\n",
        "\n",
        "def preprocess_graph(adj):\n",
        "    adj = sp.coo_matrix(adj)\n",
        "    adj_ = adj + sp.eye(adj.shape[0])\n",
        "    rowsum = np.array(adj_.sum(1))\n",
        "    degree_mat_inv_sqrt = sp.diags(np.power(rowsum, -0.5).flatten())\n",
        "    adj_normalized = adj_.dot(degree_mat_inv_sqrt).transpose().dot(degree_mat_inv_sqrt).tocoo()\n",
        "    return sparse_to_tuple(adj_normalized)\n",
        "\n",
        "\n",
        "def construct_feed_dict(adj_normalized, adj, features, placeholders):\n",
        "    feed_dict = dict()\n",
        "    feed_dict.update({placeholders['features']: features})\n",
        "    feed_dict.update({placeholders['adj']: adj_normalized})\n",
        "    feed_dict.update({placeholders['adj_orig']: adj})\n",
        "    return feed_dict\n",
        "\n",
        "\n",
        "def mask_test_edges(adj):\n",
        "    # Function to build test set with 2% positive links\n",
        "    # Remove diagonal elements\n",
        "    adj = adj - sp.dia_matrix((adj.diagonal()[np.newaxis, :], [0]), shape=adj.shape)\n",
        "    adj.eliminate_zeros()\n",
        "\n",
        "    adj_triu = sp.triu(adj)\n",
        "    adj_tuple = sparse_to_tuple(adj_triu)\n",
        "    edges = adj_tuple[0]\n",
        "    edges_all = sparse_to_tuple(adj)[0]\n",
        "    num_test = int(np.floor(edges.shape[0] / 50.))\n",
        "    num_val = int(np.floor(edges.shape[0] / 50.))\n",
        "\n",
        "    all_edge_idx = np.arange(edges.shape[0])\n",
        "    np.random.shuffle(all_edge_idx)\n",
        "    val_edge_idx = all_edge_idx[:num_val]\n",
        "    test_edge_idx = all_edge_idx[num_val:(num_val + num_test)]\n",
        "    test_edges = edges[test_edge_idx]\n",
        "    val_edges = edges[val_edge_idx]\n",
        "    train_edges = np.delete(edges, np.hstack([test_edge_idx, val_edge_idx]), axis=0)\n",
        "\n",
        "    def ismember(a, b):\n",
        "        rows_close = np.all((a - b[:, None]) == 0, axis=-1)\n",
        "        return np.any(rows_close)\n",
        "\n",
        "    test_edges_false = []\n",
        "    while len(test_edges_false) < len(test_edges):\n",
        "        n_rnd = len(test_edges) - len(test_edges_false)\n",
        "        rnd = np.random.randint(0, adj.shape[0], size=2 * n_rnd)\n",
        "        idxs_i = rnd[:n_rnd]                                        \n",
        "        idxs_j = rnd[n_rnd:]\n",
        "        for i in range(n_rnd):\n",
        "            idx_i = idxs_i[i]\n",
        "            idx_j = idxs_j[i]\n",
        "            if idx_i == idx_j:\n",
        "                continue\n",
        "            if ismember([idx_i, idx_j], edges_all):\n",
        "                continue\n",
        "            if test_edges_false:\n",
        "                if ismember([idx_j, idx_i], np.array(test_edges_false)):\n",
        "                    continue\n",
        "                if ismember([idx_i, idx_j], np.array(test_edges_false)):\n",
        "                    continue\n",
        "            test_edges_false.append([idx_i, idx_j])\n",
        "\n",
        "    val_edges_false = []\n",
        "    while len(val_edges_false) < len(val_edges):\n",
        "        n_rnd = len(val_edges) - len(val_edges_false)\n",
        "        rnd = np.random.randint(0, adj.shape[0], size=2 * n_rnd)\n",
        "        idxs_i = rnd[:n_rnd]                                        \n",
        "        idxs_j = rnd[n_rnd:]\n",
        "        for i in range(n_rnd):\n",
        "            idx_i = idxs_i[i]\n",
        "            idx_j = idxs_j[i]\n",
        "            if idx_i == idx_j:\n",
        "                continue\n",
        "            if ismember([idx_i, idx_j], train_edges):\n",
        "                continue\n",
        "            if ismember([idx_j, idx_i], train_edges):\n",
        "                continue\n",
        "            if ismember([idx_i, idx_j], val_edges):\n",
        "                continue\n",
        "            if ismember([idx_j, idx_i], val_edges):\n",
        "                continue\n",
        "            if val_edges_false:\n",
        "                if ismember([idx_j, idx_i], np.array(val_edges_false)):\n",
        "                    continue\n",
        "                if ismember([idx_i, idx_j], np.array(val_edges_false)):\n",
        "                    continue\n",
        "            val_edges_false.append([idx_i, idx_j])\n",
        "\n",
        "    # Re-build adj matrix\n",
        "    data = np.ones(train_edges.shape[0])\n",
        "    adj_train = sp.csr_matrix((data, (train_edges[:, 0], train_edges[:, 1])), shape=adj.shape)\n",
        "    adj_train = adj_train + adj_train.T\n",
        "\n",
        "    return adj_train, train_edges, val_edges, val_edges_false, test_edges, test_edges_false\n",
        "\n",
        "\n",
        "def get_roc_score(edges_pos, edges_neg):\n",
        "    feed_dict.update({placeholders['dropout']: 0})\n",
        "    emb = sess.run(model.embeddings, feed_dict=feed_dict)\n",
        "\n",
        "    def sigmoid(x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    # Predict on test set of edges\n",
        "    adj_rec = np.dot(emb, emb.T)\n",
        "    preds = []\n",
        "    pos = []\n",
        "    for e in edges_pos:\n",
        "        preds.append(sigmoid(adj_rec[e[0], e[1]]))\n",
        "        pos.append(adj_orig[e[0], e[1]])\n",
        "\n",
        "    preds_neg = []\n",
        "    neg = []\n",
        "    for e in edges_neg:\n",
        "        preds_neg.append(sigmoid(adj_rec[e[0], e[1]]))\n",
        "        neg.append(adj_orig[e[0], e[1]])\n",
        "\n",
        "    preds_all = np.hstack([preds, preds_neg])\n",
        "    labels_all = np.hstack([np.ones(len(preds)), np.zeros(len(preds))])\n",
        "    roc_score = roc_auc_score(labels_all, preds_all)\n",
        "    ap_score = average_precision_score(labels_all, preds_all)    \n",
        "    return roc_score, ap_score\n",
        "\n",
        "# to get precision\n",
        "from sklearn.metrics import plot_precision_recall_curve\n",
        "def get_pre_rec(edges_pos, edges_neg):\n",
        "    feed_dict.update({placeholders['dropout']: 0})\n",
        "    emb = sess.run(model.embeddings, feed_dict=feed_dict)\n",
        "\n",
        "    def sigmoid(x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    # Predict on test set of edges\n",
        "    adj_rec = np.dot(emb, emb.T)\n",
        "    preds = []\n",
        "    pos = []\n",
        "    for e in edges_pos:\n",
        "        preds.append(sigmoid(adj_rec[e[0], e[1]]))\n",
        "        pos.append(adj_orig[e[0], e[1]])\n",
        "\n",
        "    preds_neg = []\n",
        "    neg = []\n",
        "    for e in edges_neg:\n",
        "        preds_neg.append(sigmoid(adj_rec[e[0], e[1]]))\n",
        "        neg.append(adj_orig[e[0], e[1]])\n",
        "\n",
        "    preds_all = np.hstack([preds, preds_neg])\n",
        "    labels_all = np.hstack([np.ones(len(preds)), np.zeros(len(preds))])\n",
        "    for i in range (len(preds_all)):\n",
        "        a = np.mean(preds_all)\n",
        "        if preds_all[i]< a :\n",
        "            preds_all[i] = 0\n",
        "        else :\n",
        "            preds_all[i] = 1\n",
        "\n",
        "    recallVal = recall_score(labels_all, preds_all)    \n",
        "    precisionVal, recallVal, thresholds = precision_recall_curve(labels_all, preds_all)\n",
        "    return  precisionVal, recallVal\n",
        "\n",
        "   "
      ],
      "metadata": {
        "id": "VRY7H0BFdnRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "seed = 123\n",
        "np.random.seed(seed)\n",
        "tf.set_random_seed(seed)\n",
        "\n",
        "# Settings\n",
        "flags = tf.app.flags\n",
        "FLAGS = flags.FLAGS\n",
        "flags.DEFINE_float('learning_rate', 0.01, 'Initial learning rate.')\n",
        "flags.DEFINE_integer('epochs', 50, 'Number of epochs to train.')\n",
        "flags.DEFINE_integer('hidden1', 32, 'Number of units in hidden layer 1.')\n",
        "flags.DEFINE_integer('hidden2', 32, 'Number of units in hidden layer 2.') # originally 16\n",
        "flags.DEFINE_float('dropout', 0.1, 'Dropout rate (1 - keep probability).')"
      ],
      "metadata": {
        "id": "3KgL1UsqfZNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ROC and AP improved to 0.923 and 0.91 respectively from 0.9 and .85 when\n",
        "# hidden2 was changed to 8 from 16. With 32, ROC and AP were 0.9 and 0.85"
      ],
      "metadata": {
        "id": "3_zZ2gEZf6ZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Convolutional Layers for GCN Model"
      ],
      "metadata": {
        "id": "YUcbK1RVgCDh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphConvolution():\n",
        "    \"\"\"Basic graph convolution layer for undirected graph without edge labels.\"\"\"\n",
        "    def __init__(self, input_dim, output_dim, adj, name, dropout=0., act=tf.nn.relu):\n",
        "        self.name = name\n",
        "        self.vars = {}\n",
        "        self.issparse = False\n",
        "        with tf.variable_scope(self.name + '_vars'):\n",
        "            self.vars['weights'] = weight_variable_glorot(input_dim, output_dim, name='weights')\n",
        "        self.dropout = dropout\n",
        "        self.adj = adj\n",
        "        self.act = act\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        with tf.name_scope(self.name):        \n",
        "            x = inputs\n",
        "            x = tf.nn.dropout(x, 1-self.dropout)\n",
        "            x = tf.matmul(x, self.vars['weights'])\n",
        "            x = tf.sparse_tensor_dense_matmul(self.adj, x)\n",
        "            outputs = self.act(x)\n",
        "        return outputs\n",
        "\n",
        "\n",
        "class GraphConvolutionSparse():\n",
        "    \"\"\"Graph convolution layer for sparse inputs.\"\"\"\n",
        "    def __init__(self, input_dim, output_dim, adj, features_nonzero, name, dropout=0., act=tf.nn.relu):\n",
        "        self.name = name\n",
        "        self.vars = {}\n",
        "        self.issparse = False\n",
        "        with tf.variable_scope(self.name + '_vars'):\n",
        "            self.vars['weights'] = weight_variable_glorot(input_dim, output_dim, name='weights')\n",
        "        self.dropout = dropout\n",
        "        self.adj = adj\n",
        "        self.act = act\n",
        "        self.issparse = True\n",
        "        self.features_nonzero = features_nonzero\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        with tf.name_scope(self.name):\n",
        "            x = inputs\n",
        "            x = dropout_sparse(x, 1-self.dropout, self.features_nonzero)\n",
        "            x = tf.sparse_tensor_dense_matmul(x, self.vars['weights'])\n",
        "            x = tf.sparse_tensor_dense_matmul(self.adj, x)\n",
        "            outputs = self.act(x)\n",
        "        return outputs\n",
        "    \n",
        "    \n",
        "class InnerProductDecoder():\n",
        "    \"\"\"Decoder model layer for link prediction.\"\"\"\n",
        "    def __init__(self, input_dim, name, dropout=0., act=tf.nn.sigmoid):\n",
        "        self.name = name\n",
        "        self.issparse = False\n",
        "        self.dropout = dropout\n",
        "        self.act = act\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        with tf.name_scope(self.name):\n",
        "            inputs = tf.nn.dropout(inputs, 1-self.dropout)\n",
        "            x = tf.transpose(inputs)\n",
        "            x = tf.matmul(inputs, x)\n",
        "            x = tf.reshape(x, [-1])\n",
        "            outputs = self.act(x)\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "pFLMwYENf_UY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Specify the Architecture of our GCN Model"
      ],
      "metadata": {
        "id": "GzjJvZdogK9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GCNModel():\n",
        "    def __init__(self, placeholders, num_features, features_nonzero, name):\n",
        "        self.name = name\n",
        "        self.inputs = placeholders['features']\n",
        "        self.input_dim = num_features\n",
        "        self.features_nonzero = features_nonzero\n",
        "        self.adj = placeholders['adj']\n",
        "        self.dropout = placeholders['dropout']\n",
        "        with tf.variable_scope(self.name):\n",
        "            self.build()\n",
        "        \n",
        "    def build(self):\n",
        "        self.hidden1 = GraphConvolutionSparse(\n",
        "            name='gcn_sparse_layer',\n",
        "            input_dim=self.input_dim,\n",
        "            output_dim=FLAGS.hidden1,\n",
        "            adj=self.adj,\n",
        "            features_nonzero=self.features_nonzero,\n",
        "            act=tf.nn.relu,\n",
        "            dropout=self.dropout)(self.inputs)\n",
        "\n",
        "        self.embeddings = GraphConvolution(\n",
        "            name='gcn_dense_layer',\n",
        "            input_dim=FLAGS.hidden1,\n",
        "            output_dim=FLAGS.hidden2,\n",
        "            adj=self.adj,\n",
        "            act=lambda x: x,\n",
        "            dropout=self.dropout)(self.hidden1)\n",
        "\n",
        "        self.reconstructions = InnerProductDecoder(\n",
        "            name='gcn_decoder',\n",
        "            input_dim=FLAGS.hidden2, \n",
        "            act=lambda x: x)(self.embeddings)"
      ],
      "metadata": {
        "id": "pa6r13_egIJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Specify the GCN Optimizer"
      ],
      "metadata": {
        "id": "w1I4p67Xgi0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Optimizer():\n",
        "    def __init__(self, preds, labels, num_nodes, num_edges):\n",
        "        pos_weight = float(num_nodes**2 - num_edges) / num_edges\n",
        "        norm = num_nodes**2 / float((num_nodes**2 - num_edges) * 2)\n",
        "        \n",
        "        preds_sub = preds\n",
        "        labels_sub = labels\n",
        "\n",
        "        self.cost = norm * tf.reduce_mean(\n",
        "            tf.nn.weighted_cross_entropy_with_logits(\n",
        "                logits=preds_sub, targets=labels_sub, pos_weight=pos_weight))\n",
        "        self.optimizer = tf.train.AdamOptimizer(learning_rate=FLAGS.learning_rate)  # Adam Optimizer\n",
        "\n",
        "        self.opt_op = self.optimizer.minimize(self.cost)\n",
        "        self.grads_vars = self.optimizer.compute_gradients(self.cost)"
      ],
      "metadata": {
        "id": "Z86yNVfBgkYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the GCN Model and Evaluating its Accuracy on a Test Set"
      ],
      "metadata": {
        "id": "QtyuwTq3g0iZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adj = load_data()\n",
        "num_nodes = adj.shape[0]\n",
        "num_edges = adj.sum()\n",
        "# Featureless\n",
        "features = sparse_to_tuple(sp.identity(num_nodes))\n",
        "num_features = features[2][1]\n",
        "features_nonzero = features[1].shape[0]\n",
        "\n",
        "# Store original adjacency matrix (without diagonal entries) for later\n",
        "adj_orig = adj - sp.dia_matrix((adj.diagonal()[np.newaxis, :], [0]), shape=adj.shape)\n",
        "adj_orig.eliminate_zeros()\n",
        "\n",
        "adj_train, train_edges, val_edges, val_edges_false, test_edges, test_edges_false = mask_test_edges(adj)\n",
        "adj = adj_train\n",
        "\n",
        "adj_norm = preprocess_graph(adj)"
      ],
      "metadata": {
        "id": "f75-hfv_gyNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.app.flags.DEFINE_string('f', '', 'kernel')\n",
        "# Define placeholders\n",
        "placeholders = {\n",
        "    'features': tf.sparse_placeholder(tf.float32),\n",
        "    'adj': tf.sparse_placeholder(tf.float32),\n",
        "    'adj_orig': tf.sparse_placeholder(tf.float32),\n",
        "    'dropout': tf.placeholder_with_default(0., shape=())\n",
        "}\n",
        "\n",
        "# Create model\n",
        "model = GCNModel(placeholders, num_features, features_nonzero, name='facebook_gcn')\n",
        "\n",
        "# Create optimizer\n",
        "with tf.name_scope('optimizer'):\n",
        "    opt = Optimizer(\n",
        "        preds=model.reconstructions,\n",
        "        labels=tf.reshape(tf.sparse_tensor_to_dense(placeholders['adj_orig'], validate_indices=False), [-1]),\n",
        "        num_nodes=num_nodes,\n",
        "        num_edges=num_edges)"
      ],
      "metadata": {
        "id": "SaEopLCbg5bR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize session\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer()) # training happens\n",
        "\n",
        "adj_label = adj_train + sp.eye(adj_train.shape[0])\n",
        "adj_label = sparse_to_tuple(adj_label)\n",
        "\n",
        "# Train model\n",
        "for epoch in range(FLAGS.epochs):\n",
        "    t = time.time()\n",
        "    # Construct feed dictionary\n",
        "    feed_dict = construct_feed_dict(adj_norm, adj_label, features, placeholders)\n",
        "    feed_dict.update({placeholders['dropout']: FLAGS.dropout})\n",
        "    # One update of parameter matrices\n",
        "    _, avg_cost = sess.run([opt.opt_op, opt.cost], feed_dict=feed_dict)\n",
        "    # Performance on validation set\n",
        "    roc_curr, ap_curr = get_roc_score(val_edges, val_edges_false)\n",
        "\n",
        "   \n",
        "    print(\"Epoch:\", '%04d' % (epoch + 1), \n",
        "          \"train_loss=\", \"{:.5f}\".format(avg_cost),\n",
        "          \"val_roc=\", \"{:.5f}\".format(roc_curr),\n",
        "          \"val_ap=\", \"{:.5f}\".format(ap_curr),\n",
        "          \"time=\", \"{:.5f}\".format(time.time() - t))\n",
        "    \n",
        "print('Optimization Finished!')\n",
        "\n",
        "roc_score, ap_score = get_roc_score(test_edges, test_edges_false)\n",
        "#precision, recall = get_pre_rec(test_edges, test_edges_false)\n",
        "\n",
        "precisionVal, recallVal= get_pre_rec(test_edges, test_edges_false)\n",
        "\n",
        "\n",
        "\n",
        "test_edges[1], test_edges_false[1]\n",
        "print('Test ROC score: {:.5f}'.format(roc_score))\n",
        "print('Test AP score: {:.5f}'.format(ap_score))\n",
        "\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "WGXl4s2gg-2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for curve plotting   ------\n",
        "from sklearn.metrics import plot_precision_recall_curve\n",
        "\n",
        "# Initialize session\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "adj_label = adj_train + sp.eye(adj_train.shape[0])\n",
        "adj_label = sparse_to_tuple(adj_label)\n",
        "\n",
        "# Train model\n",
        "for epoch in range(FLAGS.epochs):\n",
        "    t = time.time()\n",
        "    # Construct feed dictionary\n",
        "    feed_dict = construct_feed_dict(adj_norm, adj_label, features, placeholders)\n",
        "    feed_dict.update({placeholders['dropout']: FLAGS.dropout})\n",
        "    # One update of parameter matrices\n",
        "    _, avg_cost = sess.run([opt.opt_op, opt.cost], feed_dict=feed_dict)\n",
        "    # Performance on validation set\n",
        "    \n",
        "    \n",
        "    #precision, recall = get_pre_rec(val_edges, val_edges_false)\n",
        "    precisionVal, recallVal= get_pre_rec(test_edges, test_edges_false)"
      ],
      "metadata": {
        "id": "096evCS9hZyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pyplot.plot(recallVal, precisionVal, marker='.', label='GCN')\n",
        "# axis labels\n",
        "pyplot.xlabel('Recall')\n",
        "pyplot.ylabel('Precision')\n",
        "# show the legend\n",
        "pyplot.legend()\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "nreDXyp5hbQZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}